Introduction of RGB

RGB
用RGB表示的图形一般都是栅格图像, 其原理源于光敏电阻.

在一个透镜系统中, 透镜将光照到光敏电阻上, 将光锥信息传给光敏电阻, 光敏电阻根据对光的敏感度不同而表现出不同的阻值; 所以当使用光敏电阻作为阵列时, 就能获取到人们所知的像素(黑白); 
根据每个光敏电阻的不同阻值R, 表示了不同的光强G1, G2,...Gn.

例如: 800 * 600 = 48w, 即代表48w像素, 图像即是由一个一个的像素组成

但一些手机和相机厂商也会有像素虚高的问题, 例如将一个2 * 2的矩阵拓展成为3 * 3的矩阵, 原来的4个像素分别位于四角, 其余的像素由这几个像素值求平均而产生.

RGB则是通过使用三个不同的光敏电阻的灰度值进而表示颜色, 这三种颜色分别为我们知道的红, 绿, 蓝色.

在神经网络中将一个图像分为红, 绿, 蓝三个通道(Channel), 默认输入图像RGB被叫做Input Channel, 同时图像还有宽度(W)和高度(H)等值.
在每一个通道里取一个块(Patch), 三个通道一共取三个块3 * W' * H'的张量, 要对其做卷积, 做完后会得到另外的卷积, 在卷积的过程中其通道, W, H都有可能发生变化, 该块在图像中开始滑动, 对每一个块进行卷积, 就会将
整个图像用数据表示. 但不管卷积的过程中有多少个通道, 其数据一定包含之前所有通道的所有数据.

卷积的运算过程 eg: 

Input: 1 * 5 * 5, Kernel(卷积核) = 3 * 3, 用Input * Kernel(做数乘, 不是矩阵乘), 最终Output = 1 * 3 * 3.
在神经网络中每次卷积可能有许多个通道, 这时就Kernel也需要相同数量的通道, Kernel的个数需要与通道的数量相同, 每个核分别卷积一个通道, 最终将每个通道的卷积所得张量求和, 就会得到卷积的结果.

在卷积时数据的W和H会缩小, 这与Kernel的大小有关

如何要让n通道的数据卷积之后变为m通道的数据, 则需要m个卷积核, 分别计算出每个1 * W' * H'的Feature map, 将其拼接即得到m * W' * H'

每个卷积核的通道数量和输入的通道数量是相同的.

所以要构造一个卷积层的话就需要四个参数: in_channels, out_channels, width, height.

卷积过程如下代码所示
//Code Start

import torch
in_channels, out_channels = 5, 10 //输入通道, 输出通道
width, height = 100, 100
kernel_size = 3 //卷积核的尺寸
batch_size = 1

input = torch.randn(batch_size(小批量), in_channels, width, height)

conv_layer = torch.nn.Conv2d(in_channels, out_channels, kernel_size = kernel_size)  //卷积核不一定是m * m, 有可能是m * n.

output = conv_layer(input)

print(input.shape)  //torch.Size([1, 5, 100, 100])
print(output.shape) //torch.Size([1, 10, 98, 98])
print(conv_layer.weight.shape)  //torch.Size([5, 10, 3, 3])

//Code End

其余的CNN中的参数

Padding: 在原始矩阵外围增添若干圈使得Input核Output的W和H不变(增添与输出和卷积层大小有关).
Stride(步长): 一般情况Stride为1, 表示每次卷积移动的格数, 可以有效降低图像的W和H.
下采样: 一般使用MaxPooling, 默认Stride = 2, 将矩阵分为2 * 2的组, 每个组挑出最大的1个元素; 当Stride = 2时, 输出图像的W和H是原来的1 / 2.

A Simple Convolution Neural Network

(batch, 1, 28, 28) -> Conv2d Layer(5 * 5, 1, 10) -> (batch, 10, 24, 24) -> Pooling Layer(2 * 2) -> (batch, 10, 12, 12) -> Conv2d Layer(5 * 5, 10, 20) -> (batch, 20, 8, 8) -> Pooling Layer(2 * 2) -> (batch, 20, 4, 4) -> Linear Layer(320, 10) -> (batch, 10)







